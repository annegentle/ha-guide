      <section xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  version="5.0"
  xml:id="_run_openstack_api_and_schedulers">

          <title>Run OpenStack API and schedulers</title>

        <section xml:id="_api_services">

            <title>API services</title>

          <para>All OpenStack projects have an API service for controlling all the resources in the Cloud.
In active/active mode, the most common setup is to scale-out these services on at least two nodes
and use load balancing and virtual IP (with HAProxy &amp; Keepalived in this setup).</para>
          <para>
            <emphasis role="strong">Configure API OpenStack services</emphasis>
          </para>
          <para>To configure our Cloud using Highly available and scalable API services, we need to ensure that:</para>
          <itemizedlist>
            <listitem>
              <para>
You use virtual IPs when configuring OpenStack Identity endpoints.
</para>
            </listitem>
            <listitem>
              <para>
All OpenStack configuration files should refer to virtual IPs.
</para>
            </listitem>
          </itemizedlist>
          <para>
            <emphasis role="strong">In case of failure</emphasis>
          </para>
          <para>The monitor check is quite simple since it just establishes a TCP connection to the API port. Comparing to the
active/passive mode using Corosync &amp; Resources Agents, we don’t check if the service is actually running.
That’s why all OpenStack API should be monitored by another tool, for example Nagios, with the goal to detect
failures in the Cloud Framework infrastructure.</para>
        </section>
        <section xml:id="_schedulers">

            <title>Schedulers</title>

          <para>OpenStack schedulers are used to determine how to dispatch compute, network and volume requests. The most
common setup is to use RabbitMQ as messaging system already documented in this guide.
Those services are connected to the messaging backend and can scale-out:</para>
          <itemizedlist>
            <listitem>
              <para>
nova-scheduler
</para>
            </listitem>
            <listitem>
              <para>
nova-conductor
</para>
            </listitem>
            <listitem>
              <para>
cinder-scheduler
</para>
            </listitem>
            <listitem>
              <para>
neutron-server
</para>
            </listitem>
            <listitem>
              <para>
ceilometer-collector
</para>
            </listitem>
            <listitem>
              <para>
heat-engine
</para>
            </listitem>
          </itemizedlist>
          <para>Please refer to the RabbitMQ section for configuring these services with multiple messaging servers.</para>
        </section>
      </section>
